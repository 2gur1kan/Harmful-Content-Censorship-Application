# Harmful-Content-Censorship-Application

In this project, a censorship application supported by Yolo V5 and V8 is aimed at automatically censoring videos containing harmful content.
To open the project, you need to run the file located at Harmful-Content-Censorship-Application\Detection\mainwindow.py.
To train your own models, you can use the provided code and dataset in the Harmful-Content-Censorship-Application\ModelTrain folder.
To review the models I have trained in detail, you can open the zip file located in the Harmful-Content-Censorship-Application\Trained_Models_Training_Files folder. This file contains the best models obtained from the training process.

**requirements**: Harmful-Content-Censorship-Application\Detection\models in unzip

*: Interface design of the application :*
![MainWindow](https://github.com/user-attachments/assets/451c621d-0311-4980-94b7-80a3cdd5385b)

***Output photos of the application :***
![sigaradetect1](https://github.com/user-attachments/assets/1ef30e96-9244-4d32-8f44-3b5a637aae66)

![sigaradetect2](https://github.com/user-attachments/assets/be0b4497-8942-445f-b3c1-6e7cc85d2cd5)

![sigaradetect3](https://github.com/user-attachments/assets/917cfe2f-7711-4804-8e2f-4127df0fa9c5)
